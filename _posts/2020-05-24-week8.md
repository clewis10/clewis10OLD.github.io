---
layout: post
title: Social Engineering & Disinformation 
excerpt: "Usable Security - Week 8"
categories: [Usable Security]
comments: true
image:
  feature: https://images.pexels.com/photos/911738/pexels-photo-911738.jpeg?auto=compress&cs=tinysrgb&dpr=3&h=750&w=1260
  credit: 
  creditlink: 
---
## Usable Security - Week 8

# Social Engineering & Disinformation 

 

This week’s topic is on social engineering and & disinformation which are two aspects of cyber security that can have profound impacts on society if not properly controlled. This is because often the people that these types of things are targeting are common people in attempts to manipulate what that person might think about something. This is an extremely dangerous area because it’s done mostly by extremist groups in to achieve some agenda.  

 

The first reading from this week comes from Michael Golebiewski and Danah Boyd, Data Voids. Data Voids speaks about some issues we know face online from places that people use to find content. Search engines. Diving into some of the things we have seen happen in the event of what they define as a Data Void and how it can affect society. They define some of the main types of voids such as breaking news, strategic new terms (“crisis actors”), outdated terms (“the Oscars”, “social justice”), fragmented concepts (“poop” and “stool”) and problematic queries (“did the holocaust happen?”). In each of these situations they are looking at it with the perspective that someone is manipulating the search engine with ideological, economic or political agendas using these tactics. This issue has been present since the start of search engines, people are always going to try to exploit the ranking for there own benefits. This has resulted in a cat and mouse game between search engine creators and the SEO industry. This has lead to link farms and bots to increase search ranks for sites so they can be the first for many search terms. People are continuing to get better at understanding how to take advantage of a bad situation such as a shooting to rewrite the news to achieve some agenda that it was made up and acted to make guns seem worse. This means that these platforms have to react and respond to these voids in order to help eliminate this kind of abuse because users hold very little control in this situation. While this is a bit up to debate I believe auto-complete and “auto-play” (from YouTube) are actually alright starts to mitigating this. Although that creates a new issue of how that are created which results in recommended engine optimization but this is at least hopping to help lead the user to the search they were looking for. With the current COVID-19 pandemic, I think Google has done a reasonable good job at trying to eliminate miss-information and limit people’s ability to monetize this situation. I think you can see this both on google and YouTube with clear links on any content that is about it to trusted authorities with the most recent information.  

 

The last reading was written by Amelia Acker and spoke about people using data to take advantage of other profiles to fake who they were. It dives into speaking about how at one time it was very easy for third parties on Facebook to gather a ton of information about users even if they didn’t use the third party. This was because if someone used it, it would automatically share information about their friends. This is just a glance into how easy it was for organization to gather massive amounts of user data without more trouble. Although I believe today this could never happen because the general awareness around personal data as complete changed since 2010 but it still shows that it extremely easy to build profiles of users based on meta-data.  

 

Overall, I think miss information and data on the internet is one of the most dangerous things that we face in the realm of cyber security. It’s so hard to quantify an attacker when they aren’t directly attacking. They are just posting fake articles and information for years and one day a search term makes that information seem legitimate to large groups of people. This also becomes difficult because it really is up to the platforms to handle this because of their (usually) global reach. Although this is something that can be help by the community by potentially giving a validity rating ability. (…but that brings in another potential aspect of abuse soo maybe not)So 
